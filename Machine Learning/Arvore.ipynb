
# -*- coding: utf-8 -*-

# --- 1. PREPARAÇÃO DO AMBIENTE ---
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Modelos do Scikit-learn
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Métricas de avaliação
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# --- 2. CARGA E LIMPEZA DE DADOS ---
# Carregando a base de dados diretamente do repositório do Kaggle no GitHub
# Usaremos apenas o arquivo de treino, que contém a variável alvo ('Survived')
url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
df = pd.read_csv(url)

print("--- Informações Iniciais do Dataset ---")
df.info()
print("\n--- Primeiras Linhas do Dataset ---")
print(df.head())
--- Informações Iniciais do Dataset ---
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB

--- Primeiras Linhas do Dataset ---
   PassengerId  Survived  Pclass  \
0            1         0       3   
1            2         1       1   
2            3         1       3   
3            4         1       1   
4            5         0       3   

                                                Name     Sex   Age  SibSp  \
0                            Braund, Mr. Owen Harris    male  22.0      1   
1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                             Heikkinen, Miss. Laina  female  26.0      0   
3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                           Allen, Mr. William Henry    male  35.0      0   

   Parch            Ticket     Fare Cabin Embarked  
0      0         A/5 21171   7.2500   NaN        S  
1      0          PC 17599  71.2833   C85        C  
2      0  STON/O2. 3101282   7.9250   NaN        S  
3      0            113803  53.1000  C123        S  
4      0            373450   8.0500   NaN        S  
# Tratando dados faltantes
# 'Age': Preencher com a mediana é uma abordagem robusta contra outliers
df['Age'] = df['Age'].fillna(df['Age'].median())

# 'Embarked': Preencher com a moda (o valor mais comum)
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])

# 'Cabin': Possui muitos valores nulos (quase 77%). A abordagem mais simples é remover a coluna.
# Poderíamos tentar extrair informação (como a primeira letra do deck), mas para este comparativo, vamos remover.
df.drop('Cabin', axis=1, inplace=True)

# Removendo colunas que não agregam valor preditivo direto para o modelo
df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
# --- 3. PRÉ-PROCESSAMENTO E ENGENHARIA DE FEATURES ---
# Convertendo variáveis categóricas em variáveis numéricas (dummy variables)
# Usamos 'drop_first=True' para evitar multicolinearidade
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

print("\n--- Dataset Após Pré-processamento ---")
print(df.head())
--- Dataset Após Pré-processamento ---
   Survived  Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  \
0         0       3  22.0      1      0   7.2500      True       False   
1         1       1  38.0      1      0  71.2833     False       False   
2         1       3  26.0      0      0   7.9250     False       False   
3         1       1  35.0      1      0  53.1000     False       False   
4         0       3  35.0      0      0   8.0500      True       False   

   Embarked_S  
0        True  
1       False  
2        True  
3        True  
4        True  
# --- 4. DIVISÃO DOS DADOS ---
# Separando as variáveis independentes (features, X) da variável dependente (alvo, y)
X = df.drop('Survived', axis=1)
y = df['Survived']

# Dividindo em conjuntos de treino e teste (80% para treino, 20% para teste)
# 'random_state' garante que a divisão seja sempre a mesma, para reprodutibilidade
# 'stratify=y' garante que a proporção de sobreviventes/não sobreviventes seja a mesma nos dois conjuntos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
# --- 5. CRIAÇÃO E TREINAMENTO DOS MODELOS ---

# Modelo 1: Árvore de Decisão
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# Modelo 2: Random Forest
# n_estimators é o número de árvores na floresta. 100 é um bom ponto de partida.
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
# --- 6. AVALIAÇÃO DETALHADA ---

def evaluate_model(model_name, y_true, y_pred):
    """Função para exibir as métricas de avaliação de forma organizada."""
    print(f"--- Avaliação do Modelo: {model_name} ---")
    
    # Acurácia Geral
    accuracy = accuracy_score(y_true, y_pred)
    print(f"Acurácia Geral: {accuracy:.4f}\n")
    
    # Relatório de Classificação (com métricas por classe)
    print("Relatório de Classificação:")
    print(classification_report(y_true, y_pred, target_names=['Não Sobreviveu (0)', 'Sobreviveu (1)']))
    
    # Matriz de Confusão
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Não Sobreviveu', 'Sobreviveu'], 
                yticklabels=['Não Sobreviveu', 'Sobreviveu'])
    plt.xlabel('Predito')
    plt.ylabel('Verdadeiro')
    plt.title(f'Matriz de Confusão - {model_name}')
    plt.show()
 
# Avaliando os dois modelos
evaluate_model("Árvore de Decisão", y_test, y_pred_dt)
--- Avaliação do Modelo: Árvore de Decisão ---
Acurácia Geral: 0.8212

Relatório de Classificação:
                    precision    recall  f1-score   support

Não Sobreviveu (0)       0.84      0.88      0.86       110
    Sobreviveu (1)       0.79      0.72      0.76        69

          accuracy                           0.82       179
         macro avg       0.81      0.80      0.81       179
      weighted avg       0.82      0.82      0.82       179


evaluate_model("Random Forest", y_test, y_pred_rf)
--- Avaliação do Modelo: Random Forest ---
Acurácia Geral: 0.8156

Relatório de Classificação:
                    precision    recall  f1-score   support

Não Sobreviveu (0)       0.83      0.87      0.85       110
    Sobreviveu (1)       0.78      0.72      0.75        69

          accuracy                           0.82       179
         macro avg       0.81      0.80      0.80       179
      weighted avg       0.81      0.82      0.81       179

